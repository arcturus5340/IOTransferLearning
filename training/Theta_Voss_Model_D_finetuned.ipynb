{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39cd82d-5cc9-45d9-b9d2-99d7def92a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn import cluster\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torch\n",
    "\n",
    "from wquantiles import quantile_1D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class ConfigStruct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69a6b27-cccc-4acf-9c9e-4d7e2e85774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ca2ef5-ed60-4c4a-a3ec-2b5403c32736",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=100,\n",
    "    batch_size=2048,\n",
    "    learning_rate=0.008, # 0.0005 ?!\n",
    "    weight_decay=1e-5,\n",
    "    dropout=0.5,  # 0.05 ?!\n",
    "    shuffle=True,\n",
    "    test_size=0.1,  # 0.2 ?!\n",
    "    split_seed=42,\n",
    "    random_seed=1234,\n",
    "    top10_apps_filter=False,\n",
    "    only_duplicates=False,\n",
    "    meancount75_filter=False,\n",
    "    isolation_forest_train=False,\n",
    "    isolation_forest_val=False,\n",
    "    isolation_forest_test=False,\n",
    "    feature_agglomeration=False,\n",
    "    feature_agglomeration_nclusters=64,\n",
    "    stratified_split=False,\n",
    "    smooth_l1_loss_beta=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef3fe7c-f99a-4f79-a36b-cb18fd4cfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigStruct(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb83280-8152-488d-a0ea-547f2202d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILENAME = \"Model_D\"\n",
    "MODEL_DIR = r\"../models\"\n",
    "MODEL_PATH = Path(MODEL_DIR, MODEL_FILENAME).with_suffix(\".pth\")\n",
    "MODEL_TUNED_PATH = Path(MODEL_DIR, MODEL_FILENAME + \"_(finetuned)\").with_suffix(\".pth\")\n",
    "\n",
    "DATASET_DIR = r\"../data/\"\n",
    "DATASET_NAME = \"theta_posix_with_apps_no_negative_outliers_no_time_witherrors\"\n",
    "DATASET_PATH = Path(DATASET_DIR, DATASET_NAME).with_suffix(\".csv\")\n",
    "\n",
    "PICKLE_DIR = r\"../models/pickle\"\n",
    "FEATUREAGGLO_NAME = r\"Model_D_(finetuned)_featureagglomeration\"\n",
    "FEATUREAGGLO_PATH = Path(PICKLE_DIR, FEATUREAGGLO_NAME).with_suffix(\".pkl\")\n",
    "\n",
    "ROBUSTSCALER_NAME = r\"Model_D_(finetuned)_robustscaler\"\n",
    "ROBUSTSCALER_PATH = Path(PICKLE_DIR, ROBUSTSCALER_NAME).with_suffix(\".pkl\")\n",
    "\n",
    "ISOLATIONFOREST_NAME = r\"Model_D_(finetuned)_isolationforest\"\n",
    "ISOLATIONFOREST_PATH = Path(PICKLE_DIR, ISOLATIONFOREST_NAME).with_suffix(\".pkl\")\n",
    "\n",
    "INTERPRETABILITY_DIR = r\"../interpretability/captum\"\n",
    "\n",
    "CSV_LOG_PATH = \"../results/training/Model_D_(finetuned)_test_loss.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856ebf59-8ed8-46b4-91af-9c96c807e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_LOG_PATH):\n",
    "    with open(CSV_LOG_PATH, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"epoch\", \"test_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f910d56c-d5d7-421d-9c75-adc96f2453d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSIX_OPENS</th>\n",
       "      <th>POSIX_FILENOS</th>\n",
       "      <th>POSIX_DUPS</th>\n",
       "      <th>POSIX_READS</th>\n",
       "      <th>POSIX_WRITES</th>\n",
       "      <th>POSIX_SEEKS</th>\n",
       "      <th>POSIX_STATS</th>\n",
       "      <th>POSIX_MMAPS</th>\n",
       "      <th>POSIX_FSYNCS</th>\n",
       "      <th>POSIX_RENAME_SOURCES</th>\n",
       "      <th>...</th>\n",
       "      <th>WRITE_1M_4M</th>\n",
       "      <th>WRITE_4M_10M</th>\n",
       "      <th>WRITE_10M_100M</th>\n",
       "      <th>WRITE_100M_1G</th>\n",
       "      <th>WRITE_1G_PLUS</th>\n",
       "      <th>rank</th>\n",
       "      <th>POSIX_TOTAL_TIME</th>\n",
       "      <th>nprocs</th>\n",
       "      <th>mean</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7891771</td>\n",
       "      <td>7861736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>424661</td>\n",
       "      <td>60035</td>\n",
       "      <td>90055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.684507</td>\n",
       "      <td>64</td>\n",
       "      <td>31.913841</td>\n",
       "      <td>-2.229334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1499</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.155456</td>\n",
       "      <td>16</td>\n",
       "      <td>11.403251</td>\n",
       "      <td>16.752206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46037</td>\n",
       "      <td>40869</td>\n",
       "      <td>0</td>\n",
       "      <td>4713059</td>\n",
       "      <td>1719073</td>\n",
       "      <td>1271774</td>\n",
       "      <td>5429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>71229.030892</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1492</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.707640</td>\n",
       "      <td>16</td>\n",
       "      <td>6.519022</td>\n",
       "      <td>-4.811382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7891771</td>\n",
       "      <td>7861736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>424661</td>\n",
       "      <td>60035</td>\n",
       "      <td>90055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.010366</td>\n",
       "      <td>64</td>\n",
       "      <td>33.631730</td>\n",
       "      <td>0.378636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   POSIX_OPENS  POSIX_FILENOS  POSIX_DUPS  POSIX_READS  POSIX_WRITES  \\\n",
       "0      7891771        7861736           0            3        424661   \n",
       "1          194            172           0           34          1499   \n",
       "2        46037          40869           0      4713059       1719073   \n",
       "3          194            172           0           34          1492   \n",
       "4      7891771        7861736           0            3        424661   \n",
       "\n",
       "   POSIX_SEEKS  POSIX_STATS  POSIX_MMAPS  POSIX_FSYNCS  POSIX_RENAME_SOURCES  \\\n",
       "0        60035        90055            0             0                     0   \n",
       "1            6           54            0             0                     0   \n",
       "2      1271774         5429            0             0                     0   \n",
       "3            6           54            0             0                     0   \n",
       "4        60035        90055            0             0                     0   \n",
       "\n",
       "   ...  WRITE_1M_4M  WRITE_4M_10M  WRITE_10M_100M  WRITE_100M_1G  \\\n",
       "0  ...            0             0               0              0   \n",
       "1  ...            0             0               0              0   \n",
       "2  ...          500             0               0              0   \n",
       "3  ...            0             0               0              0   \n",
       "4  ...            0             0               0              0   \n",
       "\n",
       "   WRITE_1G_PLUS  rank  POSIX_TOTAL_TIME  nprocs       mean      error  \n",
       "0              0     0         29.684507      64  31.913841  -2.229334  \n",
       "1              0     0         28.155456      16  11.403251  16.752206  \n",
       "2              0    -1      71229.030892     128        NaN   0.000000  \n",
       "3              0     2          1.707640      16   6.519022  -4.811382  \n",
       "4              0     0         34.010366      64  33.631730   0.378636  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_blue_waters_posix = pd.read_csv(DATASET_PATH)\n",
    "df_blue_waters_posix = df_blue_waters_posix.drop(['exe', 'lustre', 'index'],axis=1)\n",
    "df_blue_waters_posix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4db74f-dad5-47a5-bfe0-556db0046958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just fine tune with quantum espresso data\n",
    "# df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix.exe.str.contains(\"pw.x\")]\n",
    "# df_blue_waters_posix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd86af74-b044-4d0f-9e68-8c8bf10ff784",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.top10_apps_filter:\n",
    "    apps_count_series = df_blue_waters_posix.groupby(by=[\"exe\"]).count()[\"nprocs\"].sort_values(ascending=False)\n",
    "    df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix.exe.isin(apps_count_series[0:10].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63a4570-f369-4dbc-9b6b-11e2aa8c6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.only_duplicates:\n",
    "    df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix[\"mean\"].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f972f4f-fe11-437d-b4c6-652c37d42089",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.meancount75_filter:\n",
    "    mean_counts = df_blue_waters_posix.groupby(\"mean\",dropna=False)[\"mean\"].transform(\"count\")\n",
    "    mean_counts_quantile = pd.Series(mean_counts.unique()).quantile(0.75)\n",
    "    df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix.index.isin(mean_counts[mean_counts > mean_counts_quantile].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2dc028f-100a-43cb-86a6-b8767cf489ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       29.684507\n",
       "1       28.155456\n",
       "2    71229.030892\n",
       "3        1.707640\n",
       "4       34.010366\n",
       "Name: POSIX_TOTAL_TIME, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate bandwidth from input features\n",
    "POSIX_TOTAL_TIME_df = df_blue_waters_posix.pop('POSIX_TOTAL_TIME')\n",
    "POSIX_TOTAL_TIME_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6badbfea-18b2-48b7-997a-72bb2b645a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate duplicate set mean from input features and drop errors\n",
    "dup_set_means_df = df_blue_waters_posix.pop('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a04d4d-c492-4684-9ccf-b8d357f45721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSIX_OPENS</th>\n",
       "      <th>POSIX_FILENOS</th>\n",
       "      <th>POSIX_DUPS</th>\n",
       "      <th>POSIX_READS</th>\n",
       "      <th>POSIX_WRITES</th>\n",
       "      <th>POSIX_SEEKS</th>\n",
       "      <th>POSIX_STATS</th>\n",
       "      <th>POSIX_MMAPS</th>\n",
       "      <th>POSIX_FSYNCS</th>\n",
       "      <th>POSIX_RENAME_SOURCES</th>\n",
       "      <th>...</th>\n",
       "      <th>WRITE_1K_10K</th>\n",
       "      <th>WRITE_10K_100K</th>\n",
       "      <th>WRITE_100K_1M</th>\n",
       "      <th>WRITE_1M_4M</th>\n",
       "      <th>WRITE_4M_10M</th>\n",
       "      <th>WRITE_10M_100M</th>\n",
       "      <th>WRITE_100M_1G</th>\n",
       "      <th>WRITE_1G_PLUS</th>\n",
       "      <th>rank</th>\n",
       "      <th>nprocs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7891771</td>\n",
       "      <td>7861736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>424661</td>\n",
       "      <td>60035</td>\n",
       "      <td>90055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1499</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46037</td>\n",
       "      <td>40869</td>\n",
       "      <td>0</td>\n",
       "      <td>4713059</td>\n",
       "      <td>1719073</td>\n",
       "      <td>1271774</td>\n",
       "      <td>5429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1492</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7891771</td>\n",
       "      <td>7861736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>424661</td>\n",
       "      <td>60035</td>\n",
       "      <td>90055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   POSIX_OPENS  POSIX_FILENOS  POSIX_DUPS  POSIX_READS  POSIX_WRITES  \\\n",
       "0      7891771        7861736           0            3        424661   \n",
       "1          194            172           0           34          1499   \n",
       "2        46037          40869           0      4713059       1719073   \n",
       "3          194            172           0           34          1492   \n",
       "4      7891771        7861736           0            3        424661   \n",
       "\n",
       "   POSIX_SEEKS  POSIX_STATS  POSIX_MMAPS  POSIX_FSYNCS  POSIX_RENAME_SOURCES  \\\n",
       "0        60035        90055            0             0                     0   \n",
       "1            6           54            0             0                     0   \n",
       "2      1271774         5429            0             0                     0   \n",
       "3            6           54            0             0                     0   \n",
       "4        60035        90055            0             0                     0   \n",
       "\n",
       "   ...  WRITE_1K_10K  WRITE_10K_100K  WRITE_100K_1M  WRITE_1M_4M  \\\n",
       "0  ...             0               0              0            0   \n",
       "1  ...             0               0              0            0   \n",
       "2  ...          3546               0              0          500   \n",
       "3  ...             0               0              0            0   \n",
       "4  ...             0               0              0            0   \n",
       "\n",
       "   WRITE_4M_10M  WRITE_10M_100M  WRITE_100M_1G  WRITE_1G_PLUS  rank  nprocs  \n",
       "0             0               0              0              0     0      64  \n",
       "1             0               0              0              0     0      16  \n",
       "2             0               0              0              0    -1     128  \n",
       "3             0               0              0              0     2      16  \n",
       "4             0               0              0              0     0      64  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blue_waters_posix = df_blue_waters_posix.drop([\"error\"], axis=1)\n",
    "df_blue_waters_posix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21439002-5664-453d-868f-596a217f3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seeds for reproducibility\n",
    "random.seed(config.random_seed)\n",
    "np.random.seed(config.random_seed)\n",
    "\n",
    "torch.manual_seed(config.random_seed)\n",
    "torch.cuda.manual_seed_all(config.random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "454ed534-bbfd-4123-a818-69aaea1c886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_blue_waters_posix,\n",
    "                                                    POSIX_TOTAL_TIME_df,\n",
    "                                                    test_size=config.test_size,\n",
    "                                                    random_state=config.split_seed,\n",
    "                                                    stratify=df_blue_waters_posix[\"nprocs\"] if config.stratified_split else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b900ea75-b880-4e64-af5e-d70adc928df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo = cluster.FeatureAgglomeration(n_clusters=config.feature_agglomeration_nclusters)\n",
    "agglo.fit(df_blue_waters_posix)\n",
    "with open(FEATUREAGGLO_PATH,'wb') as f:\n",
    "    pickle.dump(agglo,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c78cbfe5-77de-419b-b9b7-115f948e3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.feature_agglomeration:\n",
    "    X_train = agglo.transform(X_train)\n",
    "    X_val = agglo.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69de4ef3-9ba3-478d-9909-043963f75d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input features with RobustScaler\n",
    "scaler = RobustScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eebf75ae-04b3-4f2a-a581-40b324fcca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROBUSTSCALER_PATH,'wb') as f:\n",
    "    pickle.dump(scaler,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2af2b9f-258d-4930-a6ea-ff67f7623475",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "436cc68a-8388-4423-8a9f-b97633d578b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_train = torch.Tensor(X_train_scaled).to(device)\n",
    "tensor_y_train = torch.Tensor(y_train.values).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53b4970e-2b5d-4588-8ff2-f859d9fb5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = TensorDataset(tensor_X_train, tensor_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3207048b-07ae-4621-9a81-f28adac2aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If shuffle disabled, use weighted random sampling\n",
    "if config.shuffle:\n",
    "    training_dataloader = DataLoader(training_dataset, batch_size=config.batch_size, shuffle=config.shuffle)\n",
    "else:\n",
    "    training_dataloader = DataLoader(training_dataset, batch_size=config.batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9004b778-2b08-4b47-9444-987aa2585d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_val = torch.Tensor(X_val_scaled).to(device)\n",
    "tensor_y_val = torch.Tensor(y_val.values).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4207d77a-7774-4b7d-86ab-73381a46bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = TensorDataset(tensor_X_val, tensor_y_val)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=config.batch_size)  #, shuffle=config.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ab6e97f-c16b-4992-bcfd-6e89b383dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(config.feature_agglomeration_nclusters if config.feature_agglomeration else 89, 512),\n",
    "    nn.Dropout(p=config.dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.Dropout(p=config.dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.Dropout(p=config.dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92dcb595-19d6-42da-9df5-0f50a7e20e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default Pytorch returns avg loss per minibatch elements. But since the last batch\n",
    "# (both in training and test) does not have enough instances, sum all the loss across the batches\n",
    "# and then divide it by total number of elements in the the test set.\n",
    "loss_fn = nn.SmoothL1Loss(beta=config.smooth_l1_loss_beta, reduction=\"sum\").to(device)\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d597dfe7-3400-40bd-8041-92059d482ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model...\n",
      "Current epoch: 99\n"
     ]
    }
   ],
   "source": [
    "# Load previously trained state if available\n",
    "if Path(MODEL_PATH).is_file():\n",
    "    print(\"Loading pretrained model...\")\n",
    "\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    model_epoch = checkpoint['epoch']\n",
    "\n",
    "    print(f\"Current epoch: {model_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96cc6ece-c50f-40ee-addd-f4af626c1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(list(model.children()))\n",
    "for i,layer in enumerate(model.children()):\n",
    "    if i < num_layers - 1:\n",
    "        layer.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57ab82b7-217f-4611-b286-fe77bad75434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=89, out_features=512, bias=True)\n",
       "  (1): Dropout(p=0.5, inplace=False)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (4): Dropout(p=0.5, inplace=False)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_epoch = 0\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7304c54-841e-4257-90ed-f9ec99baff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for (X, y) in training_dataloader:\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # Divide the summed loss by the number of elements in the current batch to get the average loss\n",
    "        loss = loss_fn(y, y_pred) / len(X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45091912-b016-46a6-828d-8f676aff7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in validation_dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item() \n",
    "\n",
    "    # Divide the summed test loss by the number of elements in the whole test dataset to get the average loss\n",
    "    test_loss /= len(validation_dataloader.dataset)\n",
    "\n",
    "    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fea4a6b-3d69-4c9c-96b2-36f7271e5bd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m test_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model_epoch, config\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# print(f\"Epoch {epoch + 1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test()\n\u001b[0;32m      8\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(test_loss)\n",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Divide the summed loss by the number of elements in the current batch to get the average loss\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataset.py:207\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataset.py:207\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "\n",
    "for epoch in range(model_epoch, config.epochs):\n",
    "    # print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train()\n",
    "    test_loss = test()\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    model_epoch = epoch\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    with open(CSV_LOG_PATH, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch + 1, test_loss])\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': model_epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'test_losses': test_losses\n",
    "    }, MODEL_TUNED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be4abb-0a89-4875-9699-124537e877f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_losses, label='Test Loss', color='royalblue', linewidth=2, marker='o', markersize=4)\n",
    "\n",
    "plt.title(\"Test Loss Over Epochs\", fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/training/Model_D_(finetuned)_test_loss.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3104b6c-ea67-411b-b9ba-b507cba52af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
