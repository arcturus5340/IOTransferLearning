{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e272d050-0827-462a-9563-6346768e9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn import cluster\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torch\n",
    "\n",
    "from wquantiles import quantile_1D\n",
    "\n",
    "import pdb\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class ConfigStruct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308216f0-f15b-4699-96c6-3e9cf056eca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d264ef-62d6-408a-8614-34dbc02cb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=100,\n",
    "    batch_size=256, #2048\n",
    "    learning_rate=0.008, #0.008\n",
    "    weight_decay=1e-5,\n",
    "    dropout=0.05,\n",
    "    shuffle=True,\n",
    "    test_size=0.2,\n",
    "    split_seed=42,\n",
    "    random_seed=1234,\n",
    "    top10_apps_filter=False,\n",
    "    only_duplicates=False,\n",
    "    meancount75_filter=False,\n",
    "    isolation_forest_train=False,\n",
    "    isolation_forest_val=False,\n",
    "    isolation_forest_test=False,\n",
    "    feature_agglomeration=True,\n",
    "    feature_agglomeration_nclusters=64,\n",
    "    stratified_split=False,\n",
    "    smooth_l1_loss_beta=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7011d2-1752-4532-9736-b178fddfe88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigStruct(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14590c1-e238-4b6f-af9b-769c7d055db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILENAME = \"Full_Data_Model\"\n",
    "MODEL_DIR = r\"../models/\"\n",
    "MODEL_PATH = Path(MODEL_DIR, MODEL_FILENAME).with_suffix(\".pth\")\n",
    "\n",
    "DATASET_DIR = r\"../data/\"\n",
    "DATASET_NAME = \"theta_posix_with_apps_no_negative_outliers_no_time_witherrors\"\n",
    "DATASET_PATH = Path(DATASET_DIR, DATASET_NAME).with_suffix(\".csv\")\n",
    "\n",
    "PICKLE_DIR = r\"/home/rwth1591/transfer-learning/theta/pickle\"\n",
    "FEATUREAGGLO_NAME = r\"Full_Data_Model_featureagglomeration\"\n",
    "FEATUREAGGLO_PATH = Path(PICKLE_DIR, FEATUREAGGLO_NAME).with_suffix(\".pkl\")\n",
    "ROBUSTSCALER_NAME = r\"Full_Data_Model_theta_robustscaler\"\n",
    "ROBUSTSCALER_PATH = Path(PICKLE_DIR, ROBUSTSCALER_NAME).with_suffix(\".pkl\")\n",
    "ISOLATIONFOREST_NAME = r\"Full_Data_Model_theta_isolationforest\"\n",
    "ISOLATIONFOREST_PATH = Path(PICKLE_DIR, ISOLATIONFOREST_NAME).with_suffix(\".pkl\")\n",
    "\n",
    "INTERPRETABILITY_DIR = r\"../interpretability/captum\"\n",
    "\n",
    "CSV_LOG_PATH = \"Full_Data_Model_test_loss.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "904ccb4f-9a73-4ff7-b9e4-de95ed11f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_LOG_PATH):\n",
    "    with open(CSV_LOG_PATH, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"epoch\", \"test_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8d6b78-908a-41bb-9a5b-0ba735b95839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>POSIX_OPENS</th>\n",
       "      <th>POSIX_FILENOS</th>\n",
       "      <th>POSIX_DUPS</th>\n",
       "      <th>POSIX_READS</th>\n",
       "      <th>POSIX_WRITES</th>\n",
       "      <th>POSIX_SEEKS</th>\n",
       "      <th>POSIX_STATS</th>\n",
       "      <th>POSIX_MMAPS</th>\n",
       "      <th>POSIX_FSYNCS</th>\n",
       "      <th>...</th>\n",
       "      <th>WRITE_10M_100M</th>\n",
       "      <th>WRITE_100M_1G</th>\n",
       "      <th>WRITE_1G_PLUS</th>\n",
       "      <th>rank</th>\n",
       "      <th>POSIX_TOTAL_TIME</th>\n",
       "      <th>nprocs</th>\n",
       "      <th>lustre</th>\n",
       "      <th>exe</th>\n",
       "      <th>mean</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7891771</td>\n",
       "      <td>7861736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>424661</td>\n",
       "      <td>60035</td>\n",
       "      <td>90055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.684507</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>cp2k.psmp</td>\n",
       "      <td>31.913841</td>\n",
       "      <td>-2.229334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1499</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.155456</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>pw.x</td>\n",
       "      <td>11.403251</td>\n",
       "      <td>16.752206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46037</td>\n",
       "      <td>40869</td>\n",
       "      <td>0</td>\n",
       "      <td>4713059</td>\n",
       "      <td>1719073</td>\n",
       "      <td>1271774</td>\n",
       "      <td>5429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>71229.030892</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>train.x-2.0.3-ifort_intelmpi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1492</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.707640</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>pw.x</td>\n",
       "      <td>6.519022</td>\n",
       "      <td>-4.811382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7891771</td>\n",
       "      <td>7861736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>424661</td>\n",
       "      <td>60035</td>\n",
       "      <td>90055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.010366</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>cp2k.psmp</td>\n",
       "      <td>33.631730</td>\n",
       "      <td>0.378636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  POSIX_OPENS  POSIX_FILENOS  POSIX_DUPS  POSIX_READS  POSIX_WRITES  \\\n",
       "0      0      7891771        7861736           0            3        424661   \n",
       "1      1          194            172           0           34          1499   \n",
       "2      2        46037          40869           0      4713059       1719073   \n",
       "3      3          194            172           0           34          1492   \n",
       "4      4      7891771        7861736           0            3        424661   \n",
       "\n",
       "   POSIX_SEEKS  POSIX_STATS  POSIX_MMAPS  POSIX_FSYNCS  ...  WRITE_10M_100M  \\\n",
       "0        60035        90055            0             0  ...               0   \n",
       "1            6           54            0             0  ...               0   \n",
       "2      1271774         5429            0             0  ...               0   \n",
       "3            6           54            0             0  ...               0   \n",
       "4        60035        90055            0             0  ...               0   \n",
       "\n",
       "   WRITE_100M_1G  WRITE_1G_PLUS  rank  POSIX_TOTAL_TIME  nprocs  lustre  \\\n",
       "0              0              0     0         29.684507      64       1   \n",
       "1              0              0     0         28.155456      16       1   \n",
       "2              0              0    -1      71229.030892     128       1   \n",
       "3              0              0     2          1.707640      16       1   \n",
       "4              0              0     0         34.010366      64       1   \n",
       "\n",
       "                            exe       mean      error  \n",
       "0                     cp2k.psmp  31.913841  -2.229334  \n",
       "1                          pw.x  11.403251  16.752206  \n",
       "2  train.x-2.0.3-ifort_intelmpi        NaN   0.000000  \n",
       "3                          pw.x   6.519022  -4.811382  \n",
       "4                     cp2k.psmp  33.631730   0.378636  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_blue_waters_posix = pd.read_csv(DATASET_PATH)\n",
    "df_blue_waters_posix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be5f27b-c3b9-4163-8492-d3e2ec38fc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139902, 95)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_spec = (df_blue_waters_posix.exe.str.strip().isin([\"nwchem\", \"./nwchem\"]))  # | (df_blue_waters_posix.POSIX_TOTAL_TIME >= 1e8)\n",
    "df_blue_waters_posix_nospec = df_blue_waters_posix[filter_spec == False]\n",
    "df_blue_waters_posix_nospec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4467a8-b33d-4dda-82ef-e1be0aa95d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.top10_apps_filter:\n",
    "    apps_count_series = df_blue_waters_posix.groupby(by=[\"app\"]).count()[\"nprocs\"].sort_values(ascending=False)\n",
    "    df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix.app.isin(apps_count_series[0:10].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0a127-5c22-4bb3-ad1d-bb0ae5690d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.only_duplicates:\n",
    "    df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix[\"mean\"].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b89de-1276-45bb-b008-046231c7c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.meancount75_filter:\n",
    "    mean_counts = df_blue_waters_posix.groupby(\"mean\",dropna=False)[\"mean\"].transform(\"count\")\n",
    "    mean_counts_quantile = pd.Series(mean_counts.unique()).quantile(0.75)\n",
    "    df_blue_waters_posix = df_blue_waters_posix[df_blue_waters_posix.index.isin(mean_counts[mean_counts > mean_counts_quantile].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca571c-b6b2-409c-8525-88cb37ba5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blue_waters_posix = df_blue_waters_posix.drop(['app'], axis=1)\n",
    "df_blue_waters_posix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8d6f2-908b-4f9b-9111-f6d427d563f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSIX_TOTAL_TIME_df = df_blue_waters_posix.pop('POSIX_TOTAL_TIME')\n",
    "POSIX_TOTAL_TIME_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fb50b-b8f7-4118-a6d3-5a8e5daf7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate duplicate set mean from input features and drop errors\n",
    "dup_set_means_df = df_blue_waters_posix.pop('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f60e9-2a81-4b01-ba01-c1afda573ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blue_waters_posix = df_blue_waters_posix.drop([\"error\"],axis=1)\n",
    "df_blue_waters_posix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ce3d4-709d-48d3-9291-b7d4a16bc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seeds for reproducibility\n",
    "random.seed(config.random_seed)\n",
    "np.random.seed(config.random_seed)\n",
    "\n",
    "torch.manual_seed(config.random_seed)\n",
    "torch.cuda.manual_seed_all(config.random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3321d44-e864-41d5-9c25-9b41126c3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test, dup_set_means_train, dup_set_means_test = train_test_split(df_blue_waters_posix,\n",
    "                                                    POSIX_TOTAL_TIME_df,\n",
    "                                                    dup_set_means_df,\n",
    "                                                    test_size=config.test_size,\n",
    "                                                    random_state=config.split_seed,\n",
    "                                                    stratify=df_blue_waters_posix[\"nprocs\"] if config.stratified_split else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e3765-298a-40d7-b534-b2bce0083374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset, X_val_subset, y_train_subset, y_val_subset, dup_set_means_train_subset, dup_set_means_val_subset = train_test_split(X_train,\n",
    "                                                    y_train,\n",
    "                                                    dup_set_means_train,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=config.split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e279c59-01e4-40a7-8eef-0038826ecce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(random_state=0, n_jobs=-1)\n",
    "clf.fit(X_train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5ff5d-6e4c-4f63-9b25-6385b5ded89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ISOLATIONFOREST_PATH,'wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b269e0e-bd63-415e-9bb1-12dda9aaf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset_outlier_labels = pd.Series(clf.predict(X_train_subset))\n",
    "X_val_subset_outlier_labels = pd.Series(clf.predict(X_val_subset))\n",
    "X_test_outlier_labels = pd.Series(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199ca1b-937d-4eca-be18-2efba4605bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.isolation_forest_train:\n",
    "    X_train_subset = X_train_subset.reset_index()[X_train_subset_outlier_labels == 1].drop([\"index\"],axis=1)\n",
    "    y_train_subset = y_train_subset.reset_index()[X_train_subset_outlier_labels == 1].drop([\"index\"],axis=1)\n",
    "    dup_set_means_train_subset = dup_set_means_train_subset.reset_index()[X_train_subset_outlier_labels == 1].drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d728f-d046-4cc0-a74a-7f4326734705",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.isolation_forest_val:\n",
    "    X_val_subset = X_val_subset.reset_index()[X_val_subset_outlier_labels == 1].drop([\"index\"],axis=1)\n",
    "    y_val_subset = y_val_subset.reset_index()[X_val_subset_outlier_labels == 1].drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53cfa0-d123-485e-a56d-0d870ebfd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.isolation_forest_test:\n",
    "    X_test = X_test.reset_index()[X_test_outlier_labels == 1].drop([\"index\"],axis=1)\n",
    "    y_test = y_test.reset_index()[X_test_outlier_labels == 1].drop([\"index\"],axis=1)\n",
    "    dup_set_means_test = dup_set_means_test.reset_index()[X_test_outlier_labels == 1].drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f50b3-74f5-405b-80f6-1686aa3a0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute counts for weighted random sampler as 1/duplicate_set_size\n",
    "dup_set_means_train_subset_df = pd.DataFrame(dup_set_means_train_subset)\n",
    "mean_counts = dup_set_means_train_subset_df.groupby(\"mean\",dropna=False)[\"mean\"].transform(\"count\")\n",
    "mean_counts.loc[mean_counts == 0] = 1\n",
    "weights = 1 / mean_counts\n",
    "weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b0010-ab48-44e5-810e-195618843d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(config.random_seed)\n",
    "sampler = WeightedRandomSampler(weights.to_numpy(),len(weights),replacement=True,generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5872e0-c6a0-4ae6-b9fc-972969ced690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test dataset for later analysis with captum\n",
    "# test_df = X_test.copy()\n",
    "# test_df[\"POSIX_TOTAL_TIME\"] = y_test\n",
    "# test_df = test_df.reset_index()[X_test_outlier_labels == -1].drop([\"index\"],axis=1)\n",
    "# test_df.to_csv(Path(MODEL_DIR,r\"captum_test_data.csv\"))\n",
    "# test_df.to_csv(Path(MODEL_DIR,r\"test_outliers_index_reset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3097c-5bc1-4c1a-80b6-1d815dde2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo = cluster.FeatureAgglomeration(n_clusters=config.feature_agglomeration_nclusters)\n",
    "agglo.fit(df_blue_waters_posix)\n",
    "with open(FEATUREAGGLO_PATH,'wb') as f:\n",
    "    pickle.dump(agglo,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58808f69-3b1b-4a2b-baad-b159179552d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.feature_agglomeration:\n",
    "    X_train_subset = agglo.transform(X_train_subset)\n",
    "    X_val_subset = agglo.transform(X_val_subset)\n",
    "    X_test = agglo.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66a245-df07-48c6-8aa0-4e57b3a832e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input features with RobustScaler\n",
    "scaler = RobustScaler().fit(X_train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16fe9f7-18b6-4575-ba0d-99760d9bef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROBUSTSCALER_PATH,'wb') as f:\n",
    "    pickle.dump(scaler,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f2f01-f0ed-414e-b9d9-06c727490d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset_scaled = scaler.transform(X_train_subset)\n",
    "X_val_subset_scaled = scaler.transform(X_val_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef403b-057c-41f2-beed-e4beb073480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_train = torch.Tensor(X_train_subset_scaled).to(device)\n",
    "tensor_y_train = torch.Tensor(y_train_subset.values).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5bb23c-d273-4297-b9a8-a403fa9021eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = TensorDataset(tensor_X_train, tensor_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa374-8d49-4c12-b877-790a41e7a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If shuffle disabled, use weighted random sampling\n",
    "if config.shuffle:\n",
    "    training_dataloader = DataLoader(training_dataset, batch_size=config.batch_size, shuffle=config.shuffle)\n",
    "else:\n",
    "    training_dataloader = DataLoader(training_dataset, batch_size=config.batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69603b-7ac3-4f33-af8f-28214bc9fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_val = torch.Tensor(X_val_subset_scaled).to(device)\n",
    "tensor_y_val = torch.Tensor(y_val_subset.values).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0688d-0bd4-44a5-919e-52edeb0d8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = TensorDataset(tensor_X_val, tensor_y_val)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=config.batch_size)  #, shuffle=config.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d6b91-8195-4cc7-bd7f-3211573c6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6e11f-bec3-4deb-8c64-a5a0a0bafc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_test = torch.Tensor(X_test_scaled).to(device)\n",
    "tensor_y_test = torch.Tensor(y_test.values).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f30bb0-c152-481b-bc7c-4e426ea58e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(tensor_X_test, tensor_y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8da99-61dc-4e87-aba6-f3673fda1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(config.feature_agglomeration_nclusters if config.feature_agglomeration else 89, 512),\n",
    "    nn.Dropout(p=config.dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.Dropout(p=config.dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.Dropout(p=config.dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb0546-0897-4753-aca5-5fdf72cae08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default Pytorch returns avg loss per minibatch elements. But since the last batch\n",
    "# (both in training and test) does not have enough instances, sum all the loss across the batches\n",
    "# and then divide it by total number of elements in the the test set.\n",
    "loss_fn = nn.SmoothL1Loss(beta=config.smooth_l1_loss_beta, reduction=\"sum\").to(device)\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a7136-bb68-4efa-b7bf-9f7f289cff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoch = 0\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a96668-3922-4de3-9df0-883c9db86244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    size = len(training_dataloader)\n",
    "    for (X, y) in training_dataloader:\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # Divide the summed loss by the number of elements in the current batch to get the average loss\n",
    "        loss = loss_fn(y, y_pred) / len(X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167f611-b7ff-4c0b-bd2a-37e235cc793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in validation_dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item() \n",
    "\n",
    "    # Divide the summed test loss by the number of elements in the whole test dataset to get the average loss\n",
    "    test_loss /= len(validation_dataloader.dataset)\n",
    "\n",
    "    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43061568-1931-470b-83ab-3a8e1114f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "\n",
    "for epoch in range(model_epoch, config.epochs):\n",
    "    # print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    train()\n",
    "    test_loss = test()\n",
    "\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    model_epoch = epoch\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': model_epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'test_losses': test_losses\n",
    "    }, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae877f-25a5-4cbb-992e-212a3a3e335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_losses, label='Test Loss', color='royalblue', linewidth=2, marker='o', markersize=4)\n",
    "\n",
    "plt.title(\"Test Loss Over Epochs\", fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Full_data_Model_test_loss.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b46be-0473-43aa-8c84-4498779b3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_tensor = torch.Tensor([]).to(device)\n",
    "with torch.no_grad():\n",
    "    for X,y in test_dataloader:\n",
    "        output = model(X)\n",
    "        output_as_tensor = torch.Tensor(output).to(device)\n",
    "        test_output_tensor = torch.cat((test_output_tensor,output_as_tensor))\n",
    "test_output_df = pd.DataFrame(test_output_tensor.cpu().numpy())\n",
    "test_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1ce8c-8fff-483c-ac3f-c1aa2ea9b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_errors = (test_output_df[0] - dup_set_means_test.fillna(0).reset_index()[\"mean\"]).abs()\n",
    "abs_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2972b49-8465-437d-a434-7ecd1c140078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division result will be NaN where the mean is NaN because the set has no duplicates. Median ignores NaN\n",
    "abs_errors_percent = (abs_errors / dup_set_means_test.reset_index()[\"mean\"])\n",
    "abs_errors_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852808e-8529-4bc9-ae34-45ba3e3ed7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = abs_errors_percent.median()\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba64e0-7d25-4549-9ca5-a096134eb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_set_means_test_df = pd.DataFrame(dup_set_means_test)\n",
    "mean_counts_test = dup_set_means_test_df.groupby(\"mean\",dropna=False)[\"mean\"].transform(\"count\")\n",
    "mean_counts_test.loc[mean_counts_test == 0] = 1\n",
    "weights_test = 1 / mean_counts_test\n",
    "weights_test.loc[mean_counts_test < 1] = weights_test.loc[mean_counts_test < 1]   \n",
    "weights_test_nona = weights_test.reset_index()[abs_errors_percent.isna() == False].drop([\"index\"],axis=1)[\"mean\"]\n",
    "weights_test_nona_normalized = weights_test_nona / weights_test_nona.sum()\n",
    "weighted_mae = quantile_1D(abs_errors_percent[abs_errors_percent.isna() == False].to_numpy().T,weights_test_nona_normalized.to_numpy().T,0.5)\n",
    "print(f\"Weighted MAE: {weighted_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684a201-8bef-4b2b-aa7b-1f49f86d7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Weighted MAE: {weighted_mae}\")\n",
    "test_outliers = len(X_test_outlier_labels[(X_test_outlier_labels == -1) & (dup_set_means_test.reset_index()[\"mean\"].notnull())])\n",
    "print(f\"Outliers in test set that are considered in MAE computation: {test_outliers}\")\n",
    "print(f\"Feature Agglomeration clusters: {agglo.labels_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8804ef-6298-459f-8392-1d44bec02461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
